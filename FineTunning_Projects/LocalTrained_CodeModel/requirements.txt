# Core ML Libraries
torch>=2.0.0
transformers>=4.40.0
accelerate>=0.27.0
peft>=0.8.0
bitsandbytes>=0.41.0  # For quantization (Apple Silicon compatible)

# Dataset and Training
datasets>=2.16.0
trl>=0.7.0  # Training library for RLHF and fine-tuning

# Utilities
numpy>=1.24.0
pyyaml>=6.0
tqdm>=4.66.0

# Optional but recommended
sentencepiece>=0.1.99  # For some tokenizers
protobuf>=3.20.0

# For Apple Silicon optimization
# Note: bitsandbytes may need special installation on Apple Silicon
# If issues occur, try: pip install bitsandbytes --no-build-isolation

