# Import the required libraries
import streamlit as st
import os
from pathlib import Path
from dotenv import load_dotenv
from scrapegraphai.graphs import SmartScraperGraph

# Load environment variables from root .env file
env_path = Path("/Users/anuj/Desktop/Anuj-AI-ML-Lab/.env")
load_dotenv(env_path)

# Get DeepSeek API key from environment
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")

# Set up the Streamlit app
st.title("Web Scrapping AI Agent üïµÔ∏è‚Äç‚ôÇÔ∏è")
st.caption("This app allows you to scrape a website using DeepSeek API")

if not DEEPSEEK_API_KEY:
    st.error("‚ö†Ô∏è DEEPSEEK_API_KEY not found in .env file. Please add it to your .env file in the root directory.")
    st.stop()

# Configure DeepSeek API
model = st.radio(
    "Select the model",
    ["deepseek-chat", "deepseek-reasoner"],
    index=0,
)    

graph_config = {
    "llm": {
        "api_key": DEEPSEEK_API_KEY,
        "model": f"openai/{model}",  # scrapegraphai expects provider/model format
        "base_url": "https://api.deepseek.com",
    },
}

# Get the URL of the website to scrape
url = st.text_input("Enter the URL of the website you want to scrape")
# Get the user prompt
user_prompt = st.text_input("What you want the AI agent to scrape from the website?")

# Scrape the website
if st.button("Scrape", disabled=not (url and user_prompt)):
    if url and user_prompt:
        with st.spinner("Scraping website..."):
            try:
                # Create a SmartScraperGraph object
                smart_scraper_graph = SmartScraperGraph(
                    prompt=user_prompt,
                    source=url,
                    config=graph_config
                )
                result = smart_scraper_graph.run()
                st.write(result)
            except Exception as e:
                st.error(f"Error during scraping: {str(e)}")
                st.exception(e)